"""
Algora Chat Discovery Module
Finds and ranks Telegram chats relevant to a target segment.

Usage:
    # Search mode (requires active Telethon session):
    python chat_discovery.py --segment T1 --search

    # From curated list (no Telethon needed):
    python chat_discovery.py --segment T1

    # Auto-join top N chats:
    python chat_discovery.py --segment T1 --search --join --top 10

    # Output as JSON:
    python chat_discovery.py --segment T1 --search --json
"""

import asyncio
import argparse
import json
import logging
import os
import sys
from dataclasses import dataclass, field, asdict
from datetime import datetime, timezone
from typing import Optional

logger = logging.getLogger("chat_discovery")

# ============================================================
# SEGMENT DEFINITIONS
# ============================================================
# Each segment defines: keywords for search, negative keywords to exclude,
# minimum members threshold, and curated "seed" chats known to be relevant.

SEGMENTS = {
    "T1": {
        "name": "–°–µ–ª–ª–µ—Ä—ã WB/Ozon ‚Üê –¢–æ–≤–∞—Ä—ã –∏–∑ –ö–∏—Ç–∞—è",
        "description": "Sellers on Russian marketplaces sourcing from China",
        "search_queries": [
            # Russian queries
            "—Å–µ–ª–ª–µ—Ä—ã WB",
            "—Å–µ–ª–ª–µ—Ä—ã Ozon",
            "WB –ø–∞—Ä—Ç–Ω—ë—Ä—ã",
            "–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å —á–∞—Ç",
            "—Ç–æ–≤–∞—Ä—ã –∏–∑ –ö–∏—Ç–∞—è",
            "–∑–∞–∫—É–ø–∫–∏ 1688",
            "–∑–∞–∫—É–ø–∫–∏ –ö–∏—Ç–∞–π",
            "–∫–∞—Ä–≥–æ –ö–∏—Ç–∞–π",
            "wildberries —Å–µ–ª–ª–µ—Ä",
            "ozon —Å–µ–ª–ª–µ—Ä",
            "–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å –±–∏–∑–Ω–µ—Å",
            "–∏–º–ø–æ—Ä—Ç –ö–∏—Ç–∞–π",
            "–ø–æ—Å—Ç–∞–≤—â–∏–∫–∏ –ö–∏—Ç–∞–π",
            "WB –Ω–æ–≤–∏—á–∫–∏",
            "–º–∞—Ä–∂–∏–Ω–∞–ª—å–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã",
        ],
        "positive_keywords": [
            "—Å–µ–ª–ª–µ—Ä", "wb", "wildberries", "ozon", "–æ–∑–æ–Ω", "–º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å",
            "1688", "–∫–∏—Ç–∞–π", "–∑–∞–∫—É–ø–∫", "–ø–æ—Å—Ç–∞–≤—â–∏–∫", "–∫–∞—Ä–≥–æ", "—Ñ—É–ª—Ñ–∏–ª–º–µ–Ω—Ç",
            "–º–∞—Ä–∂–∞", "—Ç–æ–≤–∞—Ä", "–Ω–∏—à–∞", "–∞–Ω–∞–ª–∏—Ç–∏–∫", "mpstats", "—é–Ω–∏—Ç",
            "fob", "—Ñ–æ–±", "–æ–ø—Ç", "–∏–º–ø–æ—Ä—Ç", "—ç–∫—Å–ø–æ—Ä—Ç",
        ],
        "negative_keywords": [
            "–∫—Ä–∏–ø—Ç–æ", "–∫–∞–∑–∏–Ω–æ", "—Å—Ç–∞–≤–∫–∏", "—Ñ–æ—Ä–µ–∫—Å", "–±–∏–Ω–∞—Ä–Ω—ã–µ",
            "–ø–∏—Ä–∞–º–∏–¥–∞", "mlm", "—Å–µ—Ç–µ–≤–æ–π", "–∑–∞—Ä–∞–±–æ—Ç–æ–∫ –±–µ–∑ –≤–ª–æ–∂–µ–Ω–∏–π",
        ],
        "min_members": 200,
        "seed_chats": [
            # Verified chats from T1_CHAT_LIST.md research (2026-02-23)
            # Format: (username, name, estimated_members, notes)
            # Priority 1: Large seller chats
            ("ozon_fbs", "–ß–ê–¢ OZON | –ö–ª—É–± –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤", 50000, "–ö—Ä—É–ø–Ω–µ–π—à–∏–π —á–∞—Ç Ozon-—Å–µ–ª–ª–µ—Ä–æ–≤"),
            ("sellersfriends", "WB Ozone | –°–≤–æ–∏ –°–µ–ª–ª–µ—Ä—ã –ß–∞—Ç", 31600, "–ê–∫—Ç–∏–≤–Ω—ã–π —á–∞—Ç WB+Ozon"),
            ("sallerschat", "WB OZON | –ú—ã —Å–µ–ª–ª–µ—Ä—ã!", 20000, "+50 –Ω–æ–≤—ã—Ö/–¥–µ–Ω—å, —Å—Ç—Ä–æ–≥–∏–µ –ø—Ä–∞–≤–∏–ª–∞"),
            ("ozon_partner", "Ozon –ß–ê–¢ –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤", 15000, "–§–æ–∫—É—Å Ozon, –ø–æ—Å—Ç–∞–≤—â–∏–∫–∏"),
            ("wb_ozon_chat", "–°–µ–ª–ª–µ—Ä—ã WB OZON", 23000, "–ú—É–ª—å—Ç–∏–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω—ã–π —á–∞—Ç"),
            # Priority 2: Niche chats (China sourcing ‚Äî exact target audience)
            ("Modul_China", "–ó–∞–∫—É–ø–∫–∏ –≤ –ö–∏—Ç–∞–µ (–ú–æ–¥—É–ª—å–±–∞–Ω–∫)", 5000, "–ó–∞–∫—É–ø–∫–∏ –Ω–∞ 1688 ‚Äî –ø—Ä—è–º–∞—è –¶–ê"),
            ("wb_ozon_marketplace", "WB & Ozon –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å", 1300, "–õ–æ–≥–∏—Å—Ç–∏–∫–∞, —Ü–µ–Ω—ã, –∑–∞–∫—É–ø–∫–∏"),
            ("marketplace_biz", "–ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å –ë–∏–∑–Ω–µ—Å", 5000, "–õ–∞–π—Ñ—Ö–∞–∫–∏ WB/Ozon, –∞–Ω–∞–ª–∏—Ç–∏–∫–∞"),
            # Priority 3: Large but noisy
            ("marketplace_pro", "PRO –ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã", 38000, "–ú–Ω–æ–≥–æ —à—É–º–∞, –Ω–æ –∏ –≤–æ–ø—Ä–æ—Å–æ–≤"),
        ],
    },
    "H6": {
        "name": "–Æ—Ä–∏—Å—Ç—ã –í–≠–î ‚Üí –≠–∫—Å–ø–æ—Ä—Ç—ë—Ä—ã/–ò–º–ø–æ—Ä—Ç—ë—Ä—ã",
        "description": "International trade lawyers and importers/exporters",
        "search_queries": [
            "–í–≠–î —é—Ä–∏—Å—Ç",
            "—Ç–∞–º–æ–∂–µ–Ω–Ω—ã–π –±—Ä–æ–∫–µ—Ä",
            "–≤–∞–ª—é—Ç–Ω—ã–π –∫–æ–Ω—Ç—Ä–æ–ª—å",
            "—Å–∞–Ω–∫—Ü–∏–∏ –±–∏–∑–Ω–µ—Å",
            "–∏–º–ø–æ—Ä—Ç —ç–∫—Å–ø–æ—Ä—Ç —á–∞—Ç",
            "—Ç–∞–º–æ–∂–Ω—è –†–§",
            "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–∞—è —Ç–æ—Ä–≥–æ–≤–ª—è",
        ],
        "positive_keywords": [
            "–≤—ç–¥", "—Ç–∞–º–æ–∂–Ω", "—Å–∞–Ω–∫—Ü–∏", "–≤–∞–ª—é—Ç–Ω", "–∏–º–ø–æ—Ä—Ç", "—ç–∫—Å–ø–æ—Ä—Ç",
            "–±—Ä–æ–∫–µ—Ä", "–¥–µ–∫–ª–∞—Ä–∞—Ü", "—Å–µ—Ä—Ç–∏—Ñ–∏–∫", "–ª–∏—Ü–µ–Ω–∑–∏",
        ],
        "negative_keywords": [
            "–∫—Ä–∏–ø—Ç–æ", "–∫–∞–∑–∏–Ω–æ", "—Å—Ç–∞–≤–∫–∏",
        ],
        "min_members": 100,
        "seed_chats": [],
    },
    "T2": {
        "name": "–ê–≤—Ç–æ–∑–∞–ø—á–∞—Å—Ç–∏ –ö–∏—Ç–∞–π ‚Üí –°–¢–û –†–§",
        "description": "Chinese auto parts suppliers and Russian service centers",
        "search_queries": [
            "–∞–≤—Ç–æ–∑–∞–ø—á–∞—Å—Ç–∏ –ö–∏—Ç–∞–π",
            "–∑–∞–ø—á–∞—Å—Ç–∏ –æ–ø—Ç–æ–º",
            "–∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å —á–∞—Ç",
            "OEM –∑–∞–ø—á–∞—Å—Ç–∏",
            "–∞–Ω–∞–ª–æ–≥–∏ –∑–∞–ø—á–∞—Å—Ç–µ–π",
        ],
        "positive_keywords": [
            "–∑–∞–ø—á–∞—Å—Ç", "–∞–≤—Ç–æ—Å–µ—Ä–≤–∏—Å", "—Å—Ç–æ", "oem", "–∞–Ω–∞–ª–æ–≥", "vin",
            "–∫–∞—Ç–∞–ª–æ–≥", "–¥–µ—Ç–∞–ª", "—Ä–µ–º–æ–Ω—Ç",
        ],
        "negative_keywords": [
            "–∫—Ä–∏–ø—Ç–æ", "–∫–∞–∑–∏–Ω–æ",
        ],
        "min_members": 100,
        "seed_chats": [],
    },
}


# ============================================================
# DATA MODEL
# ============================================================

@dataclass
class DiscoveredChat:
    """A Telegram chat discovered through search or curated list."""
    username: str                    # TG username or invite link
    title: str                       # Chat title
    members: int                     # Member count
    segment: str                     # Segment ID (T1, H6, etc.)
    source: str                      # "search", "seed", "tgstat"
    relevance_score: float = 0.0     # 0-10 composite score
    notes: str = ""                  # Human-readable notes
    joined: bool = False             # Whether we've joined
    discovered_at: str = ""          # ISO timestamp

    def __post_init__(self):
        if not self.discovered_at:
            self.discovered_at = datetime.now(timezone.utc).isoformat()


# ============================================================
# SCORING
# ============================================================

def score_chat(
    title: str,
    description: str,
    members: int,
    positive_keywords: list[str],
    negative_keywords: list[str],
    min_members: int,
) -> float:
    """
    Score a chat 0-10 based on relevance to segment.

    Components:
    - keyword_match (0-5): how many positive keywords appear in title+description
    - size_score (0-3): member count relative to min_members
    - penalty (-5): negative keywords present
    """
    text = f"{title} {description}".lower()

    # Keyword matching
    matches = sum(1 for kw in positive_keywords if kw.lower() in text)
    keyword_score = min(5.0, matches * 1.0)

    # Size scoring
    if members < min_members:
        size_score = 0.5  # Still discoverable, just small
    elif members < 1000:
        size_score = 1.0
    elif members < 5000:
        size_score = 2.0
    elif members < 15000:
        size_score = 2.5
    else:
        size_score = 3.0

    # Negative keyword penalty
    neg_matches = sum(1 for kw in negative_keywords if kw.lower() in text)
    penalty = min(5.0, neg_matches * 2.5)

    return max(0.0, min(10.0, keyword_score + size_score - penalty))


# ============================================================
# TELETHON SEARCH (requires active session)
# ============================================================

async def search_telegram(
    segment_id: str,
    session_path: str = "session/growth_agent",
    api_id: Optional[int] = None,
    api_hash: Optional[str] = None,
) -> list[DiscoveredChat]:
    """
    Search Telegram for chats matching segment keywords.
    Requires Telethon session to be authorized.
    """
    try:
        from telethon import TelegramClient
        from telethon.tl.functions.contacts import SearchRequest
    except ImportError:
        logger.error("Telethon not installed. Run: pip install telethon")
        return []

    segment = SEGMENTS.get(segment_id)
    if not segment:
        logger.error(f"Unknown segment: {segment_id}")
        return []

    api_id = api_id or int(os.getenv("TG_API_ID", "0"))
    api_hash = api_hash or os.getenv("TG_API_HASH", "")

    if not api_id or not api_hash:
        logger.error("TG_API_ID and TG_API_HASH required for search mode")
        return []

    discovered = []
    seen_ids = set()

    client = TelegramClient(session_path, api_id, api_hash)
    await client.start()

    try:
        for query in segment["search_queries"]:
            logger.info(f"Searching: '{query}'")
            try:
                result = await client(SearchRequest(q=query, limit=20))

                for chat in result.chats:
                    if chat.id in seen_ids:
                        continue
                    seen_ids.add(chat.id)

                    username = getattr(chat, "username", "") or ""
                    title = getattr(chat, "title", "") or ""
                    members = getattr(chat, "participants_count", 0) or 0

                    # Get description if available
                    description = ""
                    try:
                        full = await client.get_entity(chat)
                        if hasattr(full, "about"):
                            description = full.about or ""
                    except Exception:
                        pass

                    relevance = score_chat(
                        title=title,
                        description=description,
                        members=members,
                        positive_keywords=segment["positive_keywords"],
                        negative_keywords=segment["negative_keywords"],
                        min_members=segment["min_members"],
                    )

                    if relevance >= 2.0:
                        discovered.append(DiscoveredChat(
                            username=username or str(chat.id),
                            title=title,
                            members=members,
                            segment=segment_id,
                            source="search",
                            relevance_score=round(relevance, 1),
                            notes=f"Found via query: '{query}'",
                        ))

                # Rate limit: don't hammer TG API
                await asyncio.sleep(2)

            except Exception as e:
                logger.warning(f"Search failed for '{query}': {e}")
                await asyncio.sleep(5)

    finally:
        await client.disconnect()

    # Sort by relevance descending
    discovered.sort(key=lambda c: c.relevance_score, reverse=True)
    return discovered


# ============================================================
# SEED LIST (no Telethon needed)
# ============================================================

def get_seed_chats(segment_id: str) -> list[DiscoveredChat]:
    """Return curated seed chats for a segment."""
    segment = SEGMENTS.get(segment_id)
    if not segment:
        return []

    chats = []
    for username, title, members, notes in segment["seed_chats"]:
        relevance = score_chat(
            title=title,
            description=notes,
            members=members,
            positive_keywords=segment["positive_keywords"],
            negative_keywords=segment["negative_keywords"],
            min_members=segment["min_members"],
        )
        chats.append(DiscoveredChat(
            username=username,
            title=title,
            members=members,
            segment=segment_id,
            source="seed",
            relevance_score=round(relevance, 1),
            notes=notes,
        ))

    chats.sort(key=lambda c: c.relevance_score, reverse=True)
    return chats


# ============================================================
# AUTO-JOIN
# ============================================================

async def join_chats(
    chats: list[DiscoveredChat],
    session_path: str = "session/growth_agent",
    api_id: Optional[int] = None,
    api_hash: Optional[str] = None,
    top_n: int = 10,
) -> list[DiscoveredChat]:
    """Join top N chats from the list. Returns list of successfully joined."""
    try:
        from telethon import TelegramClient
    except ImportError:
        logger.error("Telethon not installed")
        return []

    api_id = api_id or int(os.getenv("TG_API_ID", "0"))
    api_hash = api_hash or os.getenv("TG_API_HASH", "")

    joined = []
    client = TelegramClient(session_path, api_id, api_hash)
    await client.start()

    try:
        for chat in chats[:top_n]:
            try:
                logger.info(f"Joining: @{chat.username} ({chat.title})")
                await client.get_dialogs()  # Refresh dialog list
                entity = await client.get_entity(chat.username)
                await client(
                    __import__("telethon.tl.functions.channels", fromlist=["JoinChannelRequest"])
                    .JoinChannelRequest(entity)
                )
                chat.joined = True
                joined.append(chat)
                logger.info(f"  ‚úÖ Joined: {chat.title}")
                # Don't join too fast
                await asyncio.sleep(10 + (len(joined) * 5))
            except Exception as e:
                logger.warning(f"  ‚ùå Failed to join @{chat.username}: {e}")
                await asyncio.sleep(15)
    finally:
        await client.disconnect()

    return joined


# ============================================================
# DISPLAY
# ============================================================

def display_results(chats: list[DiscoveredChat], segment_id: str):
    """Print formatted results to console."""
    segment = SEGMENTS.get(segment_id, {})
    print(f"\n{'='*70}")
    print(f"  CHAT DISCOVERY: {segment.get('name', segment_id)}")
    print(f"  Found: {len(chats)} chats")
    print(f"{'='*70}\n")

    print(f"{'#':<4} {'Score':<7} {'Members':<9} {'Source':<8} {'Chat'}")
    print(f"{'-'*4} {'-'*6} {'-'*8} {'-'*7} {'-'*40}")

    for i, chat in enumerate(chats, 1):
        score_bar = "‚ñà" * int(chat.relevance_score) + "‚ñë" * (10 - int(chat.relevance_score))
        joined_mark = " ‚úÖ" if chat.joined else ""
        print(
            f"{i:<4} {chat.relevance_score:<7.1f} {chat.members:<9,} {chat.source:<8} "
            f"@{chat.username} ‚Äî {chat.title}{joined_mark}"
        )
        if chat.notes:
            print(f"     {score_bar}  üí¨ {chat.notes}")
        print()


def export_json(chats: list[DiscoveredChat]) -> str:
    """Export results as JSON string."""
    return json.dumps(
        [asdict(c) for c in chats],
        ensure_ascii=False,
        indent=2,
    )


# ============================================================
# MAIN
# ============================================================

async def main():
    parser = argparse.ArgumentParser(description="Algora Chat Discovery")
    parser.add_argument("--segment", required=True, help="Segment ID (T1, H6, T2, etc.)")
    parser.add_argument("--search", action="store_true", help="Search Telegram (requires Telethon session)")
    parser.add_argument("--join", action="store_true", help="Auto-join top chats")
    parser.add_argument("--top", type=int, default=10, help="Number of top chats to join (default: 10)")
    parser.add_argument("--json", action="store_true", help="Output as JSON")
    parser.add_argument("--session", default="session/growth_agent", help="Telethon session path")
    parser.add_argument("--output", default=None, help="Save results to file")
    args = parser.parse_args()

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s",
    )

    if args.segment not in SEGMENTS:
        print(f"‚ùå Unknown segment: {args.segment}")
        print(f"   Available: {', '.join(SEGMENTS.keys())}")
        sys.exit(1)

    # Collect chats from all sources
    all_chats: list[DiscoveredChat] = []

    # 1. Seed chats (always available)
    seeds = get_seed_chats(args.segment)
    all_chats.extend(seeds)
    logger.info(f"Loaded {len(seeds)} seed chats")

    # 2. Telegram search (optional)
    if args.search:
        searched = await search_telegram(args.segment, session_path=args.session)
        # Deduplicate by username
        existing = {c.username for c in all_chats}
        for chat in searched:
            if chat.username not in existing:
                all_chats.append(chat)
                existing.add(chat.username)
        logger.info(f"Found {len(searched)} chats via search ({len(all_chats)} total after dedup)")

    # Sort by score
    all_chats.sort(key=lambda c: c.relevance_score, reverse=True)

    # 3. Auto-join
    if args.join:
        joined = await join_chats(all_chats, session_path=args.session, top_n=args.top)
        logger.info(f"Joined {len(joined)} chats")

    # Output
    if args.json:
        result = export_json(all_chats)
        if args.output:
            with open(args.output, "w") as f:
                f.write(result)
            print(f"Saved to {args.output}")
        else:
            print(result)
    else:
        display_results(all_chats, args.segment)

    if args.output and not args.json:
        with open(args.output, "w") as f:
            f.write(export_json(all_chats))
        print(f"\nJSON saved to {args.output}")


if __name__ == "__main__":
    asyncio.run(main())
